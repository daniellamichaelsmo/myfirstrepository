{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
            },
            "source": [
                "# Checkpoint Three: Cleaning Data\n",
                "\n",
                "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
                "\n",
                "My dataset:\n",
                "\n",
                "Import the necessary libraries and create your dataframe(s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {
                "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
            },
            "outputs": [],
            "source": [
                "#Import via condas\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['id', 'dateAdded', 'dateUpdated', 'address', 'categories',\n",
                            "       'primaryCategories', 'city', 'claimed', 'country', 'cuisines',\n",
                            "       'descriptions.dateSeen', 'descriptions.sourceURLs',\n",
                            "       'descriptions.value', 'facebookPageURL', 'features.key',\n",
                            "       'features.value', 'hours.day', 'hours.dept', 'hours.hour', 'imageURLs',\n",
                            "       'isClosed', 'keys', 'languagesSpoken', 'latitude', 'longitude',\n",
                            "       'menuPageURL', 'menus.amountMax', 'menus.amountMin', 'menus.category',\n",
                            "       'menus.currency', 'menus.dateSeen', 'menus.description', 'menus.name',\n",
                            "       'menus.sourceURLs', 'name', 'paymentTypes', 'phones', 'postalCode',\n",
                            "       'priceRangeCurrency', 'priceRangeMin', 'priceRangeMax', 'province',\n",
                            "       'sic', 'sourceURLs', 'twitter', 'websites', 'yearOpened'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Load and examine the dataset\n",
                "Restaurant_data_df = pd.read_csv(\"Datafiniti_Vegetarian_and_Vegan_Restaurants.csv\")\n",
                "Restaurant_data_df.columns\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
            },
            "source": [
                "## Missing Data\n",
                "\n",
                "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {
                "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['id', 'dateAdded', 'dateUpdated', 'address', 'categories',\n",
                            "       'primaryCategories', 'city', 'country', 'cuisines', 'imageURLs', 'keys',\n",
                            "       'latitude', 'longitude', 'menuPageURL', 'menus.amountMax',\n",
                            "       'menus.amountMin', 'menus.category', 'menus.currency', 'menus.dateSeen',\n",
                            "       'menus.description', 'menus.name', 'menus.sourceURLs', 'name',\n",
                            "       'paymentTypes', 'phones', 'postalCode', 'priceRangeCurrency',\n",
                            "       'priceRangeMin', 'priceRangeMax', 'province', 'sourceURLs', 'websites'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 59,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Some of my data columns a missing more than 80% data\n",
                "#Calculate fraction of missing values\n",
                "missing_fraction = Restaurant_data_df.isnull().mean()\n",
                "\n",
                "#Select columns where more than 80% of data is missing\n",
                "columns_to_drop = missing_fraction[missing_fraction > 0.8].index\n",
                "\n",
                "#Drop columns with more than 80% missing values\n",
                "Restaurant_data_df.drop(columns=columns_to_drop, inplace=True)\n",
                "\n",
                "#Check the remaining columns\n",
                "Restaurant_data_df.columns\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
            },
            "source": [
                "## Irregular Data\n",
                "\n",
                "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([nan, 'American Express,VISA', 'Cash', 'American Express', 'AMEX',\n",
                            "       'Mastercard,Visa,American Express,Diners Club',\n",
                            "       'American Express,Mastercard,Visa', 'Visa,MasterCard',\n",
                            "       'master card,amex,visa',\n",
                            "       'American Express,Diners Club,Mastercard,Visa',\n",
                            "       'Visa,American Express',\n",
                            "       'amex,discover,master card,visa,Mastercard,Discover,Visa,American Express',\n",
                            "       'American Express,Visa,Discover,Cash,Mastercard',\n",
                            "       'discover,visa,amex,mastercard,MasterCard',\n",
                            "       'Mastercard,Discover,Visa,American Express,Check',\n",
                            "       'Mastercard,Visa', 'Mastercard,Discover,Visa,American Express',\n",
                            "       'Discover,Visa',\n",
                            "       'American Express,Diners Club,Discover,Mastercard,Visa',\n",
                            "       'Mastercard,Visa,American Express',\n",
                            "       'Mastercard,Discover,Visa,American Express,Diners Club,diners club',\n",
                            "       'amex', 'American Express,Mastercard,Visa,discover', 'mastercard',\n",
                            "       'Mastercard',\n",
                            "       'Mastercard,Discover,Visa,American Express,Diners Club',\n",
                            "       'amex,mastercard,discover,visa,AMEX',\n",
                            "       'amex,discover,mastercard,visa', 'Cash,Mastercard,Visa',\n",
                            "       'American Express,Discover,Mastercard,Visa,amex,visa,discover,master card',\n",
                            "       'American Express,Mastercard,Visa,Discover',\n",
                            "       'American Express,Cash,Debit Card,Mastercard,Visa',\n",
                            "       'American Express,Discover,Mastercard,Visa',\n",
                            "       'discover,mastercard,amex', 'visa', 'AMEX,American Express',\n",
                            "       'Mastercard,Discover,Visa,Travelers Check,American Express',\n",
                            "       'discover,amex', 'American Express,MasterCard', 'amex,visa',\n",
                            "       'American Express,Debit Card,Discover,Mastercard', 'MasterCard',\n",
                            "       'Cash,Check,Discover,Mastercard,Visa'], dtype=object)"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Examples of multi-value column needing to be cleaned\n",
                "Restaurant_data_df['paymentTypes'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1131                                                  NaN\n",
                            "8971                                                  NaN\n",
                            "1543                                          acqua panna\n",
                            "2709                                      daily selection\n",
                            "408                                                   NaN\n",
                            "4555    a smooth blend of peanut butterampcomma banana...\n",
                            "2817                                                  NaN\n",
                            "8018                                                  NaN\n",
                            "7297    Elbow Macaroni with your choice of Creamy 3 Ch...\n",
                            "1254                                                  NaN\n",
                            "8736                                                  NaN\n",
                            "5514                                                  NaN\n",
                            "3981    Romaine Organic Chickpeas Local Feta Kalamata ...\n",
                            "4048    Two pieces of multigrain toast topped with Spi...\n",
                            "9899                                                  NaN\n",
                            "Name: menus.description, dtype: object"
                        ]
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#One of the messiest columns, lots of encoding issues in our string\n",
                "Restaurant_data_df[\"menus.description\"].sample(15)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
            },
            "source": [
                "## Unnecessary Data\n",
                "\n",
                "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {
                "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['id', 'dateAdded', 'dateUpdated', 'address', 'categories',\n",
                            "       'primaryCategories', 'city', 'country', 'cuisines', 'keys', 'latitude',\n",
                            "       'longitude', 'menus.amountMax', 'menus.amountMin', 'menus.category',\n",
                            "       'menus.currency', 'menus.dateSeen', 'menus.description', 'menus.name',\n",
                            "       'name', 'paymentTypes', 'phones', 'postalCode', 'priceRangeCurrency',\n",
                            "       'priceRangeMin', 'priceRangeMax', 'province', 'websites'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 62,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Drop columns for URL data\n",
                "def drop_urls(dataframe):\n",
                "    url_columns = [col for col in dataframe.columns if 'URL' in col]\n",
                "    dataframe.drop(columns=url_columns, inplace=True)\n",
                "    return dataframe\n",
                "\n",
                "Restaurant_data_df = drop_urls(Restaurant_data_df)\n",
                "Restaurant_data_df.columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " Viewing the code in Excel and in Step 2 shows that many of the columns have multi-value data, along with encoding issues, spacing, and capitalization. I chose to rename columns in Excel and take notes about them since the sheet was so messy. These notes explane changes and next steps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {
                "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "' Renaming columns in excel and notes - All names were changed/capitalized via Excel\\n\\'id\\', -- Clean\\n\\'dateAdded\\', -- Will shorten format to date only in python\\n\\'dateUpdated\\', -- Will shorten format to date only in python\\n\\'address\\', -- Clean\\n\\'categories\\', -- Multi-value\\n\\'primaryCategories\\', -- Renamed to \"Service Category\" in excel, multi-value\\n\\'city\\', -- Clean\\n\\'country\\', -- Deleted in excel - every entry is the same\\n\\'cuisines\\', Multi-value column, may need small amount of cleaning for spacing\\n\\'keys\\', -- Clean\\n\\'latitude\\' -- Decimal formatted in excel (all equal amount of decimals)\\n\\'longitude\\', Decimal formatted in excel\\n\\'menus.amountMax\\', -- Decimal formatted in excel($)\\n\\'menus.amountMin\\', -- Decimal formatted in excel($)\\n\\'menus.category\\', -- Renamed to \"Menu Category\" in excel, cleaning needed\\n\\'menus.currency\\', -- Deleted in excel, every entry is the same\\n\\'menus.dateSeen\\', -- May drop column\\n\\'menus.description\\', -- Needs cleaning for encoding errors\\n\\'menus.name\\', Renamed to \"Menu Item Name\" in excel, some cleaning needed\\n\\'name\\', -- Renamed to \"Restaurant Name\" in excel, clean\\n\\'paymentTypes\\', -- Renamed to \"Payment Types\" in excel, needs cleaning, multi-value\\n\\'phones\\', --renamed to \"Phone Number\", will change to boolean in python\\n\\'postalCode\\', -- Clean\\n\\'priceRangeCurrency\\', -- Deleted in excel, every entry is the same\\n\\'priceRangeMin\\', -- Deleted in excel - same as priceRange Max\\n\\'priceRangeMax\\', -- decimal formatted in excel($), Renamed \"MenuItemPrice\"\\n\\'province\\', -- Renamed to \"State\" in excel, clean\\n\\'websites\\', -- Change to boolean in python\\n'"
                        ]
                    },
                    "execution_count": 63,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "''' Renaming columns in excel and notes - All names were changed/capitalized via Excel\n",
                "'id', -- Clean\n",
                "'dateAdded', -- Will shorten format to date only in python\n",
                "'dateUpdated', -- Will shorten format to date only in python\n",
                "'address', -- Clean\n",
                "'categories', -- Multi-value\n",
                "'primaryCategories', -- Renamed to \"Service Category\" in excel, multi-value\n",
                "'city', -- Clean\n",
                "'country', -- Deleted in excel - every entry is the same\n",
                "'cuisines', Multi-value column, may need small amount of cleaning for spacing\n",
                "'keys', -- Clean\n",
                "'latitude' -- Decimal formatted in excel (all equal amount of decimals)\n",
                "'longitude', Decimal formatted in excel\n",
                "'menus.amountMax', -- Decimal formatted in excel($)\n",
                "'menus.amountMin', -- Decimal formatted in excel($)\n",
                "'menus.category', -- Renamed to \"Menu Category\" in excel, cleaning needed\n",
                "'menus.currency', -- Deleted in excel, every entry is the same\n",
                "'menus.dateSeen', -- May drop column\n",
                "'menus.description', -- Needs cleaning for encoding errors\n",
                "'menus.name', Renamed to \"Menu Item Name\" in excel, some cleaning needed\n",
                "'name', -- Renamed to \"Restaurant Name\" in excel, clean\n",
                "'paymentTypes', -- Renamed to \"Payment Types\" in excel, needs cleaning, multi-value\n",
                "'phones', --renamed to \"Phone Number\", will change to boolean in python\n",
                "'postalCode', -- Clean\n",
                "'priceRangeCurrency', -- Deleted in excel, every entry is the same\n",
                "'priceRangeMin', -- Deleted in excel - same as priceRange Max\n",
                "'priceRangeMax', -- decimal formatted in excel($), Renamed \"MenuItemPrice\"\n",
                "'province', -- Renamed to \"State\" in excel, clean\n",
                "'websites', -- Change to boolean in python\n",
                "'''\n",
                "## ()-identifer value, []-online platform related, $-ready to use, *Explore/Clean, ^-boolean\n",
                "# All Updated Name\n",
                "# (ID) [DateAdded] [DateUpdated]\n",
                "# Address$\tCategories*\tService Category*\t\n",
                "# City$ \tCuisines*\t(Key)\t\n",
                "# Latitude$ \tLongitude$\t MenuItemPrice$ \t\n",
                "# MenuCategory*\t[MenuDateSeen]\tMenuDescription* MenuItemName*\t\n",
                "# RestaurantName$\tPaymentTypes*  PhoneNumber^\tPostalCode$\t\n",
                "# PriceRangeMin$\tPriceRangeMax$\tState$\tWebsite^\n",
                "# paymentTypes_list\tpaymentTypes_clean\t\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['ID', 'DateAdded', 'DateUpdated', 'Address', 'Categories',\n",
                            "       'Service Category', 'City', 'Cuisines', 'Key', 'Latitude', 'Longitude',\n",
                            "       ' MenuItemPrice ', 'MenuCategory', 'MenuDateSeen', 'MenuDescription',\n",
                            "       'MenuItemName', 'RestaurantName', 'PaymentTypes', 'PhoneNumber',\n",
                            "       'PostalCode', ' PriceRangeMin ', ' PriceRangeMax ', 'State', 'Website',\n",
                            "       'paymentTypes_list', 'paymentTypes_clean'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Loading New CSV\n",
                "Restaurant_data_cleaned_df = pd.read_csv(\"Restaurant_data_cleaned.csv\")\n",
                "Restaurant_data_cleaned_df.columns\n",
                "#the remaining columns are ready for further cleaning.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
            },
            "source": [
                "## Inconsistent Data\n",
                "\n",
                "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process.\n",
                "- I am checking for consistency in our Longitude/Latitude data to make sure it is within range. The data is largely irregular and not inconsistent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### At this point I have  \n",
                "Explored data, done preliminary cleaning, renamed columns, deleted unusable or unnessary columns, and assessed further steps. \n",
                "From here I will - \n",
                "- Clean string columns\n",
                "- Convert dates to date only\n",
                "- Clean multi-value columns \n",
                "- Switch some data to Boolean\n",
                "- Validate latitude/longitude\n",
                "- Remove duplicates, and \n",
                "- extract the file again.\n",
                "- *some of this has already been done with our payment info. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {
                "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
            },
            "outputs": [],
            "source": [
                "#Phone Number and Website columns converted to boolean so we can asses them from a yes/no perspective\n",
                "Restaurant_data_cleaned_df[\"HasPhone\"] = (\n",
                "    Restaurant_data_cleaned_df[\"PhoneNumber\"].notna()\n",
                ")\n",
                "\n",
                "Restaurant_data_cleaned_df[\"HasWebsite\"] = (\n",
                "    Restaurant_data_cleaned_df[\"Website\"].notna()\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Validate Latitude and Longitude columns\n",
                "Restaurant_data_cleaned_df = Restaurant_data_cleaned_df[\n",
                "    Restaurant_data_cleaned_df[\"Latitude\"].between(-90, 90) &\n",
                "    Restaurant_data_cleaned_df[\"Longitude\"].between(-180, 180)\n",
                "]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Convert datetime to date only\n",
                "Restaurant_data_cleaned_df[\"DateAdded\"] = (\n",
                "    pd.to_datetime(Restaurant_data_cleaned_df[\"DateAdded\"], errors=\"coerce\")\n",
                "    .dt.date\n",
                ")\n",
                "\n",
                "Restaurant_data_cleaned_df[\"DateUpdated\"] = (\n",
                "    pd.to_datetime(Restaurant_data_cleaned_df[\"DateUpdated\"], errors=\"coerce\")\n",
                "    .dt.date\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Cleaning string columns\n",
                "string_columns = Restaurant_data_cleaned_df.select_dtypes(include=\"object\").columns\n",
                "\n",
                "for col in string_columns:\n",
                "    Restaurant_data_cleaned_df[col] = (\n",
                "        Restaurant_data_cleaned_df[col]\n",
                "        .astype(str)\n",
                "        .str.replace(\"ampamp\", \"&\", regex=False)\n",
                "        .str.replace(\"&amp;\", \"&\", regex=False)\n",
                "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
                "        .str.strip()\n",
                "        .replace(\"nan\", pd.NA)\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_multivalue_column(series):\n",
                "    cleaned = (\n",
                "        series\n",
                "        .str.lower()\n",
                "        .str.replace(r\"\\s*,\\s*\", \", \", regex=True)\n",
                "        .str.replace(\",+\", \",\", regex=True)\n",
                "        .str.strip(\" ,\")\n",
                "    )\n",
                "\n",
                "    return cleaned.apply(\n",
                "        lambda x: \", \".join(dict.fromkeys(x.split(\", \"))) if pd.notna(x) else x\n",
                "    )\n",
                "\n",
                "\n",
                "Restaurant_data_cleaned_df[\"Categories_clean\"] = normalize_multivalue_column(\n",
                "    Restaurant_data_cleaned_df[\"Categories\"]\n",
                ")\n",
                "Restaurant_data_cleaned_df[\"Categories_list\"] = (\n",
                "    Restaurant_data_cleaned_df[\"Categories_clean\"].str.split(\", \")\n",
                ")\n",
                "\n",
                "\n",
                "Restaurant_data_cleaned_df[\"ServiceCategory_clean\"] = normalize_multivalue_column(\n",
                "    Restaurant_data_cleaned_df[\"Service Category\"]\n",
                ")\n",
                "Restaurant_data_cleaned_df[\"ServiceCategory_list\"] = (\n",
                "    Restaurant_data_cleaned_df[\"ServiceCategory_clean\"].str.split(\", \")\n",
                ")\n",
                "\n",
                "\n",
                "Restaurant_data_cleaned_df[\"Cuisines_clean\"] = normalize_multivalue_column(\n",
                "    Restaurant_data_cleaned_df[\"Cuisines\"]\n",
                ")\n",
                "Restaurant_data_cleaned_df[\"Cuisines_list\"] = (\n",
                "    Restaurant_data_cleaned_df[\"Cuisines_clean\"].str.split(\", \")\n",
                ")\n",
                "\n",
                "\n",
                "Restaurant_data_cleaned_df[\"PaymentTypes_clean\"] = normalize_multivalue_column(\n",
                "    Restaurant_data_cleaned_df[\"PaymentTypes\"]\n",
                ")\n",
                "Restaurant_data_cleaned_df[\"PaymentTypes_list\"] = (\n",
                "    Restaurant_data_cleaned_df[\"PaymentTypes_clean\"].str.split(\", \")\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Rechecking work in Excel - deleted excess columns and keeping cleaned, list columns.\n",
                "Seeing further issues in - 'menu description' and 'menu item name' with encoding leakage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_cleaned_df = pd.read_csv(\"Restaurant_data_cleaned_final.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#This step took a lot of tries since I kept finding more encoding errors\n",
                "def decode_text(series):\n",
                "    cleaned = (\n",
                "        series.astype(str)\n",
                "        #Fix common HTML-style encodings\n",
                "        .str.replace(\"ampcomma\", \",\", regex=False)\n",
                "        .str.replace(\"ampapos\", \"'\", regex=False)\n",
                "        .str.replace(\"amp39\", \"'\", regex=False)\n",
                "        .str.replace(\"ampquot\", '\"', regex=False)\n",
                "        .str.replace(\"ampamp\", \"&\", regex=False)\n",
                "        #Remove any remaining 'amp'\n",
                "        .str.replace(\"amp\", \"\", regex=False)\n",
                "        #Normalize punctuation spacing\n",
                "        .str.replace(r\"\\s*,\\s*\", \", \", regex=True)\n",
                "        .str.replace(r'\\s*\"\\s*', '\"', regex=True)\n",
                "        .str.replace(r\"\\s*'\\s*\", \"'\", regex=True)\n",
                "        .str.replace(r\"\\s*&\\s*\", \" & \", regex=True)\n",
                "        #Collapse extra spaces\n",
                "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
                "        .str.strip()\n",
                "        #Replace literal 'nan' with pd.NA\n",
                "        .replace(\"nan\", pd.NA)\n",
                "    )\n",
                "    return cleaned\n",
                "\n",
                "# Apply to your DataFrame\n",
                "final_cleaned_df[\"MenuDescription\"] = decode_text(\n",
                "    final_cleaned_df[\"MenuDescription\"]\n",
                ")\n",
                "final_cleaned_df[\"MenuItemName\"] = decode_text(\n",
                "    final_cleaned_df[\"MenuItemName\"]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['ID', 'DateAdded', 'DateUpdated', 'Address', 'City', 'Key', 'Latitude',\n",
                            "       'Longitude', ' MenuItemPrice ', 'MenuCategory', 'MenuDescription',\n",
                            "       'MenuItemName', 'RestaurantName', 'PostalCode', ' PriceRangeMin ',\n",
                            "       ' PriceRangeMax ', 'State', 'HasPhone', 'HasWebsite', 'Categories_list',\n",
                            "       'ServiceCategory_list', 'Cuisines_list', 'PaymentTypes_list'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 74,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "final_cleaned_df[\"MenuItemName\"].sample(15)\n",
                "#Cleaned columns are looking much better, replaced old columns with new columns via excel\n",
                "final_cleaned_df.columns\n",
                "#Export the final cleaned DataFrame to a new CSV\n",
                "#final_cleaned_df.to_csv('Vegan_Vegetarian_Restaurants.csv', index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
            },
            "source": [
                "## Summarize Your Results\n",
                "\n",
                "Make note of your answers to the following questions.\n",
                "\n",
                "1. Did you find all four types of dirty data in your dataset?\n",
                "    The data is very messy however it was quite consistent, this is most likely due to most of the data being descriptive. There was a lot of irregular data when it came to formatting and encoding errors - the data is much more usable at this point.\n",
                "    Some data was already clean such as our time based columns, urls, ect but not all was necesary for our analysis.\n",
                "2. Did the process of cleaning your data give you new insights into your dataset?\n",
                "    Cleaning the data definitely made me excited to load my final csv into Tableau to see how the data appears - there is a wealth of descriptive data so I will be working to find paralells between things like names, ingredients, and counts of items/restaurants by location\n",
                "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
                "    Our multi-value columns will work well with 'wildcard' functions for filtering during our tableau visualizations, very excited to see what we can derive from our data!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "data_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
